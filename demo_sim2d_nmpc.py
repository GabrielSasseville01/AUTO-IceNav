"""Demo script for ship ice navigation using Neural MPC planner
Similar to demo_sim2d_ship_ice_navigation.py but uses Neural MPC planner.
Implements receding horizon replanning with 50m increments.
"""
import argparse
import os
import pickle
import time
from multiprocessing import Process, Pipe, Queue
from queue import Empty

import numpy as np

from ship_ice_planner.experiments.generate_rand_exp import build_obs_dicts
from ship_ice_planner.sim2d import sim
from ship_ice_planner.utils.utils import DotDict


def demo(cfg_file: str,
         exp_config_file: str,
         ice_concentration: float,
         ice_field_idx: int,
         start: list = None,
         goal: list = None,
         show_anim=True,
         output_dir: str = None,
         debug=False,
         logging=False,
         log_level=10,
         replan_horizon: float = 50.0):
    """
    Run Neural MPC demo with receding horizon replanning
    
    Args:
        replan_horizon: Distance in meters to plan ahead before replanning (default: 50m)
    """
    print('Neural MPC 2D simulation start with receding horizon replanning')
    print(f'Replan horizon: {replan_horizon}m')

    # load config
    cfg = DotDict.load_from_file(cfg_file)
    cfg.cfg_file = cfg_file

    # update parameters
    cfg.anim.show = show_anim
    cfg.output_dir = output_dir
    if output_dir and show_anim:
        cfg.anim.save = True  # cannot show and save anim at same time
        cfg.anim.show = False

    # Set horizon for replanning
    cfg.horizon = replan_horizon  # Use replan horizon for planning

    # load ice field data
    # Check if this is a Copernicus config file
    use_copernicus = os.getenv('USE_COPERNICUS', 'false').lower() == 'true'
    
    if use_copernicus:
        # Load Copernicus-based experiment config
        with open(exp_config_file, 'rb') as f:
            exp_config = pickle.load(f)
            # Find closest concentration match
            concentrations = sorted(exp_config['exp'].keys())
            closest_conc = min(concentrations, key=lambda x: abs(x - ice_concentration))
            if closest_conc in exp_config['exp']:
                if ice_field_idx in exp_config['exp'][closest_conc]:
                    exp = exp_config['exp'][closest_conc][ice_field_idx]
                else:
                    # Use first available index
                    available_indices = sorted(exp_config['exp'][closest_conc].keys())
                    if available_indices:
                        exp = exp_config['exp'][closest_conc][available_indices[0]]
                        print(f"Warning: ice_field_idx {ice_field_idx} not found, using {available_indices[0]}")
                    else:
                        raise ValueError(f"No ice fields found for concentration {closest_conc}")
            else:
                raise ValueError(f"No ice fields found for concentration {ice_concentration}")
    else:
        # Load standard experiment config
        with open(exp_config_file, 'rb') as f:
            # can either load the experiment config generated by generate_rand_exp.py
            # or can simply load obstacle data encoded as a list of lists
            exp = pickle.load(f)
            if type(exp) is list:
                exp = {'obstacles': exp}
            else:
                exp = exp['exp'][ice_concentration][ice_field_idx]

    # Get final goal
    final_goal = goal if goal is not None else exp.get('goal', cfg.ship.goal_pos)
    if start is not None:
        exp['ship_state'] = start
        initial_state = start
    else:
        initial_state = exp.get('ship_state', cfg.ship.start_pos)
    
    # Store final goal in config for reference
    cfg.final_goal = final_goal
    
    # Set initial sub-goal (first 50m ahead)
    if isinstance(initial_state, (list, np.ndarray)) and len(initial_state) >= 2:
        initial_y = initial_state[1] if len(initial_state) > 1 else 0
    else:
        initial_y = 0
    
    sub_goal_y = min(initial_y + replan_horizon, final_goal[1])
    sub_goal = [final_goal[0], sub_goal_y]
    exp['goal'] = sub_goal
    # Store final goal in metadata so planner can access it
    if 'metadata' not in exp:
        exp['metadata'] = {}
    exp['metadata']['final_goal'] = final_goal
    
    print(f'Initial state: {initial_state}')
    print(f'Final goal: {final_goal}')
    print(f'Initial sub-goal (first {replan_horizon}m): {sub_goal}')

    # Use the standard sim2d with replanning enabled
    # The planner will automatically replan when it receives new state updates
    # We'll configure it to replan every time the ship advances by replan_horizon
    cfg.sim.planner_timeout = 5.0  # Allow time for replanning
    cfg.max_replan = None  # Allow infinite replans until goal reached
    
    # Enable replanning in the planner
    # The neural_mpc planner should handle this automatically via the queue updates

    sim(cfg=cfg,
        debug=debug,          # enable planner debugging mode
        logging=logging,      # enable planner logs
        log_level=log_level,  # log level for planner https://docs.python.org/3/library/logging.html#levels
        init_queue=exp        # first message sent to planner process
        )


if __name__ == '__main__':
    from ship_ice_planner import FULL_SCALE_SIM_EXP_CONFIG, FULL_SCALE_SIM_PARAM_CONFIG

    # setup arg parser
    parser = argparse.ArgumentParser(description='Ship ice navigation demo with Neural MPC. '
                                                 'Runs a single simulation using neural model predictive control.')
    parser.add_argument('exp_config_file', nargs='?', type=str, help='File path to experiment config pickle file '
                                                                     'generated by generate_rand_exp.py',
                        default=FULL_SCALE_SIM_EXP_CONFIG)
    parser.add_argument('planner_config_file', nargs='?', type=str, help='File path to planner and simulation '
                                                                         'parameter config yaml file (see configs/)',
                        default='configs/sim2d_nmpc_config.yaml')
    parser.add_argument('-c', dest='ice_concentration', type=float,
                        help='Pick an ice concentration from {0.2, 0.3, 0.4, 0.5}', default=0.5)
    parser.add_argument('-i', dest='ice_field_idx', type=int,
                        help='Pick an ice field from {0, 1, ..., 99}', default=1)
    parser.add_argument('-s', '--start', nargs=3, metavar=('x', 'y', 'psi'), type=float,
                        help='initial ship position (x, y) in meters and heading (psi) in radians',
                        default=None)
    parser.add_argument('-g', '--goal', nargs=2, metavar=('x', 'y'), type=float,
                        help='goal position (x, y) in meters', default=None)
    parser.add_argument('--no_anim', action='store_true', help='Disable rendering (significantly speeds up sim!)')
    parser.add_argument('--output_dir', type=str, default=None, help='Directory path to store output data')
    parser.add_argument('-d', '--debug', action='store_true', help='Debug mode')
    parser.add_argument('-l', '--logging', action='store_true', help='Logging mode')
    parser.add_argument('-ll', '--log_level', type=int, default=10, help='Logging level')
    parser.add_argument('--replan_horizon', type=float, default=50.0,
                       help='Replanning horizon in meters (default: 50m)')

    args = parser.parse_args()

    print('Launching Neural MPC ship ice navigation demo...\nCmd-line arguments:'
          '\n\tExperiment config file: %s'
          '\n\tPlanner config file: %s'
          '\n\tIce concentration: %s'
          '\n\tIce field index: %s'
          '\n\tStart: %s'
          '\n\tGoal: %s'
          '\n\tShow live animation: %s'
          '\n\tOutput directory: %s'
          '\n\tDebug: %s'
          '\n\tLogging: %s'
          '\n\tLog level: %s' % (args.exp_config_file, args.planner_config_file, args.ice_concentration,
                                 args.ice_field_idx, args.start, args.goal, not args.no_anim, args.output_dir,
                                 args.debug, args.logging, args.log_level))

    demo(cfg_file=args.planner_config_file,
         exp_config_file=args.exp_config_file,
         ice_concentration=args.ice_concentration,
         ice_field_idx=args.ice_field_idx,
         start=args.start,
         goal=args.goal,
         show_anim=not args.no_anim,
         output_dir=args.output_dir,
         debug=args.debug,
         logging=args.logging,
         log_level=args.log_level,
         replan_horizon=args.replan_horizon)
